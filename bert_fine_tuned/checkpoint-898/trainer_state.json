{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 898,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011135857461024499,
      "grad_norm": 1.6152721643447876,
      "learning_rate": 1.977728285077951e-05,
      "loss": 0.6913,
      "step": 10
    },
    {
      "epoch": 0.022271714922048998,
      "grad_norm": 3.6554229259490967,
      "learning_rate": 1.955456570155902e-05,
      "loss": 0.6135,
      "step": 20
    },
    {
      "epoch": 0.0334075723830735,
      "grad_norm": 3.582219362258911,
      "learning_rate": 1.933184855233853e-05,
      "loss": 0.4752,
      "step": 30
    },
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 5.29104471206665,
      "learning_rate": 1.910913140311804e-05,
      "loss": 0.3618,
      "step": 40
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 2.574537992477417,
      "learning_rate": 1.888641425389755e-05,
      "loss": 0.2393,
      "step": 50
    },
    {
      "epoch": 0.066815144766147,
      "grad_norm": 26.807310104370117,
      "learning_rate": 1.866369710467706e-05,
      "loss": 0.2666,
      "step": 60
    },
    {
      "epoch": 0.0779510022271715,
      "grad_norm": 0.8089177012443542,
      "learning_rate": 1.8440979955456574e-05,
      "loss": 0.1487,
      "step": 70
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 3.421419620513916,
      "learning_rate": 1.8218262806236084e-05,
      "loss": 0.0899,
      "step": 80
    },
    {
      "epoch": 0.10022271714922049,
      "grad_norm": 33.52993392944336,
      "learning_rate": 1.799554565701559e-05,
      "loss": 0.1364,
      "step": 90
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 0.2313523143529892,
      "learning_rate": 1.77728285077951e-05,
      "loss": 0.0521,
      "step": 100
    },
    {
      "epoch": 0.12249443207126949,
      "grad_norm": 0.18566511571407318,
      "learning_rate": 1.755011135857461e-05,
      "loss": 0.0606,
      "step": 110
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 23.271806716918945,
      "learning_rate": 1.7327394209354123e-05,
      "loss": 0.4231,
      "step": 120
    },
    {
      "epoch": 0.1447661469933185,
      "grad_norm": 19.230504989624023,
      "learning_rate": 1.7104677060133633e-05,
      "loss": 0.2359,
      "step": 130
    },
    {
      "epoch": 0.155902004454343,
      "grad_norm": 24.813858032226562,
      "learning_rate": 1.6881959910913143e-05,
      "loss": 0.2645,
      "step": 140
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 0.2556268572807312,
      "learning_rate": 1.665924276169265e-05,
      "loss": 0.1694,
      "step": 150
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.17251120507717133,
      "learning_rate": 1.643652561247216e-05,
      "loss": 0.2124,
      "step": 160
    },
    {
      "epoch": 0.18930957683741648,
      "grad_norm": 0.17326124012470245,
      "learning_rate": 1.6213808463251673e-05,
      "loss": 0.22,
      "step": 170
    },
    {
      "epoch": 0.20044543429844097,
      "grad_norm": 7.532440185546875,
      "learning_rate": 1.5991091314031182e-05,
      "loss": 0.1544,
      "step": 180
    },
    {
      "epoch": 0.21158129175946547,
      "grad_norm": 10.000791549682617,
      "learning_rate": 1.5768374164810692e-05,
      "loss": 0.1002,
      "step": 190
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 4.287952899932861,
      "learning_rate": 1.5545657015590202e-05,
      "loss": 0.2338,
      "step": 200
    },
    {
      "epoch": 0.23385300668151449,
      "grad_norm": 14.670480728149414,
      "learning_rate": 1.5322939866369712e-05,
      "loss": 0.1149,
      "step": 210
    },
    {
      "epoch": 0.24498886414253898,
      "grad_norm": 3.0864641666412354,
      "learning_rate": 1.5100222717149222e-05,
      "loss": 0.1654,
      "step": 220
    },
    {
      "epoch": 0.2561247216035635,
      "grad_norm": 0.07681185752153397,
      "learning_rate": 1.4877505567928732e-05,
      "loss": 0.053,
      "step": 230
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 26.789112091064453,
      "learning_rate": 1.4654788418708241e-05,
      "loss": 0.2098,
      "step": 240
    },
    {
      "epoch": 0.27839643652561247,
      "grad_norm": 0.06920748949050903,
      "learning_rate": 1.4432071269487751e-05,
      "loss": 0.0093,
      "step": 250
    },
    {
      "epoch": 0.289532293986637,
      "grad_norm": 0.05637634918093681,
      "learning_rate": 1.4209354120267263e-05,
      "loss": 0.0079,
      "step": 260
    },
    {
      "epoch": 0.30066815144766146,
      "grad_norm": 0.05322752892971039,
      "learning_rate": 1.3986636971046773e-05,
      "loss": 0.1389,
      "step": 270
    },
    {
      "epoch": 0.311804008908686,
      "grad_norm": 0.04378684237599373,
      "learning_rate": 1.3763919821826281e-05,
      "loss": 0.0902,
      "step": 280
    },
    {
      "epoch": 0.32293986636971045,
      "grad_norm": 0.17017686367034912,
      "learning_rate": 1.354120267260579e-05,
      "loss": 0.0394,
      "step": 290
    },
    {
      "epoch": 0.33407572383073497,
      "grad_norm": 4.255444526672363,
      "learning_rate": 1.3318485523385302e-05,
      "loss": 0.128,
      "step": 300
    },
    {
      "epoch": 0.34521158129175944,
      "grad_norm": 45.862823486328125,
      "learning_rate": 1.3095768374164812e-05,
      "loss": 0.1694,
      "step": 310
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.0315035842359066,
      "learning_rate": 1.2873051224944322e-05,
      "loss": 0.0966,
      "step": 320
    },
    {
      "epoch": 0.3674832962138085,
      "grad_norm": 0.044298719614744186,
      "learning_rate": 1.2650334075723832e-05,
      "loss": 0.0508,
      "step": 330
    },
    {
      "epoch": 0.37861915367483295,
      "grad_norm": 0.0383329875767231,
      "learning_rate": 1.242761692650334e-05,
      "loss": 0.0271,
      "step": 340
    },
    {
      "epoch": 0.3897550111358575,
      "grad_norm": 0.03283708542585373,
      "learning_rate": 1.2204899777282853e-05,
      "loss": 0.0384,
      "step": 350
    },
    {
      "epoch": 0.40089086859688194,
      "grad_norm": 0.03488392010331154,
      "learning_rate": 1.1982182628062361e-05,
      "loss": 0.0699,
      "step": 360
    },
    {
      "epoch": 0.41202672605790647,
      "grad_norm": 0.027460092678666115,
      "learning_rate": 1.1759465478841871e-05,
      "loss": 0.0139,
      "step": 370
    },
    {
      "epoch": 0.42316258351893093,
      "grad_norm": 0.04252110794186592,
      "learning_rate": 1.1536748329621381e-05,
      "loss": 0.0029,
      "step": 380
    },
    {
      "epoch": 0.43429844097995546,
      "grad_norm": 0.28191477060317993,
      "learning_rate": 1.1314031180400893e-05,
      "loss": 0.125,
      "step": 390
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.3865166902542114,
      "learning_rate": 1.1091314031180403e-05,
      "loss": 0.0045,
      "step": 400
    },
    {
      "epoch": 0.45657015590200445,
      "grad_norm": 0.026779020205140114,
      "learning_rate": 1.0868596881959912e-05,
      "loss": 0.067,
      "step": 410
    },
    {
      "epoch": 0.46770601336302897,
      "grad_norm": 17.52695655822754,
      "learning_rate": 1.0645879732739422e-05,
      "loss": 0.0707,
      "step": 420
    },
    {
      "epoch": 0.47884187082405344,
      "grad_norm": 53.73906707763672,
      "learning_rate": 1.042316258351893e-05,
      "loss": 0.2575,
      "step": 430
    },
    {
      "epoch": 0.48997772828507796,
      "grad_norm": 0.04392467439174652,
      "learning_rate": 1.0200445434298442e-05,
      "loss": 0.0228,
      "step": 440
    },
    {
      "epoch": 0.5011135857461024,
      "grad_norm": 0.024207379668951035,
      "learning_rate": 9.977728285077952e-06,
      "loss": 0.0528,
      "step": 450
    },
    {
      "epoch": 0.512249443207127,
      "grad_norm": 0.06362365931272507,
      "learning_rate": 9.755011135857462e-06,
      "loss": 0.004,
      "step": 460
    },
    {
      "epoch": 0.5233853006681515,
      "grad_norm": 0.02260073646903038,
      "learning_rate": 9.532293986636973e-06,
      "loss": 0.0166,
      "step": 470
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 1.6187858581542969,
      "learning_rate": 9.309576837416481e-06,
      "loss": 0.0033,
      "step": 480
    },
    {
      "epoch": 0.5456570155902004,
      "grad_norm": 0.02593449503183365,
      "learning_rate": 9.086859688195991e-06,
      "loss": 0.0851,
      "step": 490
    },
    {
      "epoch": 0.5567928730512249,
      "grad_norm": 0.031160350888967514,
      "learning_rate": 8.864142538975503e-06,
      "loss": 0.1403,
      "step": 500
    },
    {
      "epoch": 0.5679287305122495,
      "grad_norm": 0.030510855838656425,
      "learning_rate": 8.641425389755011e-06,
      "loss": 0.1923,
      "step": 510
    },
    {
      "epoch": 0.579064587973274,
      "grad_norm": 0.02030019462108612,
      "learning_rate": 8.418708240534522e-06,
      "loss": 0.0974,
      "step": 520
    },
    {
      "epoch": 0.5902004454342984,
      "grad_norm": 0.021264588460326195,
      "learning_rate": 8.195991091314032e-06,
      "loss": 0.009,
      "step": 530
    },
    {
      "epoch": 0.6013363028953229,
      "grad_norm": 0.03563340753316879,
      "learning_rate": 7.973273942093542e-06,
      "loss": 0.1176,
      "step": 540
    },
    {
      "epoch": 0.6124721603563474,
      "grad_norm": 0.05513240024447441,
      "learning_rate": 7.750556792873052e-06,
      "loss": 0.0779,
      "step": 550
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 51.20429992675781,
      "learning_rate": 7.527839643652561e-06,
      "loss": 0.1375,
      "step": 560
    },
    {
      "epoch": 0.6347438752783965,
      "grad_norm": 0.04832080379128456,
      "learning_rate": 7.305122494432072e-06,
      "loss": 0.0873,
      "step": 570
    },
    {
      "epoch": 0.6458797327394209,
      "grad_norm": 13.166449546813965,
      "learning_rate": 7.082405345211582e-06,
      "loss": 0.062,
      "step": 580
    },
    {
      "epoch": 0.6570155902004454,
      "grad_norm": 0.028147637844085693,
      "learning_rate": 6.859688195991092e-06,
      "loss": 0.0047,
      "step": 590
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 0.01956803910434246,
      "learning_rate": 6.636971046770601e-06,
      "loss": 0.0161,
      "step": 600
    },
    {
      "epoch": 0.6792873051224945,
      "grad_norm": 0.3339445888996124,
      "learning_rate": 6.414253897550112e-06,
      "loss": 0.0725,
      "step": 610
    },
    {
      "epoch": 0.6904231625835189,
      "grad_norm": 0.024362746626138687,
      "learning_rate": 6.191536748329622e-06,
      "loss": 0.1576,
      "step": 620
    },
    {
      "epoch": 0.7015590200445434,
      "grad_norm": 44.037330627441406,
      "learning_rate": 5.9688195991091325e-06,
      "loss": 0.1632,
      "step": 630
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.02797837182879448,
      "learning_rate": 5.7461024498886416e-06,
      "loss": 0.0031,
      "step": 640
    },
    {
      "epoch": 0.7238307349665924,
      "grad_norm": 0.02340131439268589,
      "learning_rate": 5.523385300668151e-06,
      "loss": 0.0221,
      "step": 650
    },
    {
      "epoch": 0.734966592427617,
      "grad_norm": 0.04199462756514549,
      "learning_rate": 5.300668151447662e-06,
      "loss": 0.0233,
      "step": 660
    },
    {
      "epoch": 0.7461024498886414,
      "grad_norm": 0.06682347506284714,
      "learning_rate": 5.077951002227172e-06,
      "loss": 0.0018,
      "step": 670
    },
    {
      "epoch": 0.7572383073496659,
      "grad_norm": 4.367738246917725,
      "learning_rate": 4.855233853006682e-06,
      "loss": 0.0981,
      "step": 680
    },
    {
      "epoch": 0.7683741648106904,
      "grad_norm": 5.1179423332214355,
      "learning_rate": 4.632516703786192e-06,
      "loss": 0.1464,
      "step": 690
    },
    {
      "epoch": 0.779510022271715,
      "grad_norm": 4.153134822845459,
      "learning_rate": 4.4097995545657015e-06,
      "loss": 0.0114,
      "step": 700
    },
    {
      "epoch": 0.7906458797327395,
      "grad_norm": 0.03435039520263672,
      "learning_rate": 4.187082405345212e-06,
      "loss": 0.0463,
      "step": 710
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 4.184886932373047,
      "learning_rate": 3.964365256124722e-06,
      "loss": 0.0068,
      "step": 720
    },
    {
      "epoch": 0.8129175946547884,
      "grad_norm": 2.38962721824646,
      "learning_rate": 3.741648106904232e-06,
      "loss": 0.1361,
      "step": 730
    },
    {
      "epoch": 0.8240534521158129,
      "grad_norm": 0.21132290363311768,
      "learning_rate": 3.518930957683742e-06,
      "loss": 0.0343,
      "step": 740
    },
    {
      "epoch": 0.8351893095768375,
      "grad_norm": 1.8066397905349731,
      "learning_rate": 3.2962138084632516e-06,
      "loss": 0.0121,
      "step": 750
    },
    {
      "epoch": 0.8463251670378619,
      "grad_norm": 0.03456136956810951,
      "learning_rate": 3.073496659242762e-06,
      "loss": 0.0584,
      "step": 760
    },
    {
      "epoch": 0.8574610244988864,
      "grad_norm": 0.030675580725073814,
      "learning_rate": 2.8507795100222718e-06,
      "loss": 0.077,
      "step": 770
    },
    {
      "epoch": 0.8685968819599109,
      "grad_norm": 0.02194928005337715,
      "learning_rate": 2.628062360801782e-06,
      "loss": 0.1455,
      "step": 780
    },
    {
      "epoch": 0.8797327394209354,
      "grad_norm": 55.764923095703125,
      "learning_rate": 2.405345211581292e-06,
      "loss": 0.0347,
      "step": 790
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.029713084921240807,
      "learning_rate": 2.182628062360802e-06,
      "loss": 0.048,
      "step": 800
    },
    {
      "epoch": 0.9020044543429844,
      "grad_norm": 0.09007222950458527,
      "learning_rate": 1.959910913140312e-06,
      "loss": 0.0588,
      "step": 810
    },
    {
      "epoch": 0.9131403118040089,
      "grad_norm": 0.06651900708675385,
      "learning_rate": 1.7371937639198219e-06,
      "loss": 0.0483,
      "step": 820
    },
    {
      "epoch": 0.9242761692650334,
      "grad_norm": 0.028016433119773865,
      "learning_rate": 1.514476614699332e-06,
      "loss": 0.0363,
      "step": 830
    },
    {
      "epoch": 0.9354120267260579,
      "grad_norm": 0.019018910825252533,
      "learning_rate": 1.291759465478842e-06,
      "loss": 0.0663,
      "step": 840
    },
    {
      "epoch": 0.9465478841870824,
      "grad_norm": 44.682979583740234,
      "learning_rate": 1.069042316258352e-06,
      "loss": 0.1046,
      "step": 850
    },
    {
      "epoch": 0.9576837416481069,
      "grad_norm": 0.02934405766427517,
      "learning_rate": 8.463251670378619e-07,
      "loss": 0.067,
      "step": 860
    },
    {
      "epoch": 0.9688195991091314,
      "grad_norm": 0.031368549913167953,
      "learning_rate": 6.23608017817372e-07,
      "loss": 0.0647,
      "step": 870
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.02266920544207096,
      "learning_rate": 4.00890868596882e-07,
      "loss": 0.1009,
      "step": 880
    },
    {
      "epoch": 0.9910913140311804,
      "grad_norm": 0.28923043608665466,
      "learning_rate": 1.7817371937639199e-07,
      "loss": 0.0025,
      "step": 890
    }
  ],
  "logging_steps": 10,
  "max_steps": 898,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 951645791944704.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
