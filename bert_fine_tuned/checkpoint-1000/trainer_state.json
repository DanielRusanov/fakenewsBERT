{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005,
      "grad_norm": 1.875901222229004,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.6785,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9521210193634033,
      "learning_rate": 1.98e-05,
      "loss": 0.5712,
      "step": 20
    },
    {
      "epoch": 0.015,
      "grad_norm": 2.778719902038574,
      "learning_rate": 1.97e-05,
      "loss": 0.4114,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.518348693847656,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.2992,
      "step": 40
    },
    {
      "epoch": 0.025,
      "grad_norm": 1.202729344367981,
      "learning_rate": 1.95e-05,
      "loss": 0.1459,
      "step": 50
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8260303735733032,
      "learning_rate": 1.94e-05,
      "loss": 0.1435,
      "step": 60
    },
    {
      "epoch": 0.035,
      "grad_norm": 2.4693446159362793,
      "learning_rate": 1.93e-05,
      "loss": 0.0982,
      "step": 70
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5918174982070923,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0879,
      "step": 80
    },
    {
      "epoch": 0.045,
      "grad_norm": 3.959378242492676,
      "learning_rate": 1.91e-05,
      "loss": 0.1954,
      "step": 90
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5082175731658936,
      "learning_rate": 1.9e-05,
      "loss": 0.2032,
      "step": 100
    },
    {
      "epoch": 0.055,
      "grad_norm": 11.291218757629395,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.3995,
      "step": 110
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2461722493171692,
      "learning_rate": 1.88e-05,
      "loss": 0.1172,
      "step": 120
    },
    {
      "epoch": 0.065,
      "grad_norm": 2.782269239425659,
      "learning_rate": 1.8700000000000004e-05,
      "loss": 0.2522,
      "step": 130
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8531797528266907,
      "learning_rate": 1.86e-05,
      "loss": 0.0771,
      "step": 140
    },
    {
      "epoch": 0.075,
      "grad_norm": 50.881752014160156,
      "learning_rate": 1.8500000000000002e-05,
      "loss": 0.0733,
      "step": 150
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10384689271450043,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.009,
      "step": 160
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.05833185464143753,
      "learning_rate": 1.83e-05,
      "loss": 0.0481,
      "step": 170
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2964856028556824,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.1297,
      "step": 180
    },
    {
      "epoch": 0.095,
      "grad_norm": 26.1927490234375,
      "learning_rate": 1.8100000000000003e-05,
      "loss": 0.4217,
      "step": 190
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.739838600158691,
      "learning_rate": 1.8e-05,
      "loss": 0.3509,
      "step": 200
    },
    {
      "epoch": 0.105,
      "grad_norm": 8.016301155090332,
      "learning_rate": 1.79e-05,
      "loss": 0.1523,
      "step": 210
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11972979456186295,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 0.0102,
      "step": 220
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.07054568082094193,
      "learning_rate": 1.77e-05,
      "loss": 0.1159,
      "step": 230
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.057815488427877426,
      "learning_rate": 1.76e-05,
      "loss": 0.0684,
      "step": 240
    },
    {
      "epoch": 0.125,
      "grad_norm": 6.406992435455322,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.182,
      "step": 250
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0771021917462349,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.1279,
      "step": 260
    },
    {
      "epoch": 0.135,
      "grad_norm": 21.30171012878418,
      "learning_rate": 1.73e-05,
      "loss": 0.1632,
      "step": 270
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6408418416976929,
      "learning_rate": 1.72e-05,
      "loss": 0.0339,
      "step": 280
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.20681697130203247,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 0.2302,
      "step": 290
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3169402778148651,
      "learning_rate": 1.7e-05,
      "loss": 0.1033,
      "step": 300
    },
    {
      "epoch": 0.155,
      "grad_norm": 4.0128984451293945,
      "learning_rate": 1.69e-05,
      "loss": 0.0474,
      "step": 310
    },
    {
      "epoch": 0.16,
      "grad_norm": 12.169703483581543,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.1564,
      "step": 320
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.04531673714518547,
      "learning_rate": 1.67e-05,
      "loss": 0.0095,
      "step": 330
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.038961395621299744,
      "learning_rate": 1.66e-05,
      "loss": 0.0896,
      "step": 340
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.06168569251894951,
      "learning_rate": 1.65e-05,
      "loss": 0.017,
      "step": 350
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.032375454902648926,
      "learning_rate": 1.64e-05,
      "loss": 0.0798,
      "step": 360
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.03981344401836395,
      "learning_rate": 1.63e-05,
      "loss": 0.107,
      "step": 370
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.04365255683660507,
      "learning_rate": 1.62e-05,
      "loss": 0.1217,
      "step": 380
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.04538218677043915,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 0.2851,
      "step": 390
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.03760799020528793,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.1396,
      "step": 400
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.044155750423669815,
      "learning_rate": 1.5900000000000004e-05,
      "loss": 0.1729,
      "step": 410
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.524603843688965,
      "learning_rate": 1.58e-05,
      "loss": 0.0078,
      "step": 420
    },
    {
      "epoch": 0.215,
      "grad_norm": 5.935935020446777,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 0.1906,
      "step": 430
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.05879503861069679,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0358,
      "step": 440
    },
    {
      "epoch": 0.225,
      "grad_norm": 3.080880641937256,
      "learning_rate": 1.55e-05,
      "loss": 0.1709,
      "step": 450
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1476314514875412,
      "learning_rate": 1.54e-05,
      "loss": 0.1924,
      "step": 460
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.046574756503105164,
      "learning_rate": 1.5300000000000003e-05,
      "loss": 0.003,
      "step": 470
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3748883903026581,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0823,
      "step": 480
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.21736988425254822,
      "learning_rate": 1.5100000000000001e-05,
      "loss": 0.0671,
      "step": 490
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.02613697201013565,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.0143,
      "step": 500
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.036392662674188614,
      "learning_rate": 1.4900000000000001e-05,
      "loss": 0.0941,
      "step": 510
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.038336578756570816,
      "learning_rate": 1.48e-05,
      "loss": 0.0296,
      "step": 520
    },
    {
      "epoch": 0.265,
      "grad_norm": 4.529181480407715,
      "learning_rate": 1.4700000000000002e-05,
      "loss": 0.213,
      "step": 530
    },
    {
      "epoch": 0.27,
      "grad_norm": 15.915634155273438,
      "learning_rate": 1.46e-05,
      "loss": 0.0956,
      "step": 540
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.0359029620885849,
      "learning_rate": 1.45e-05,
      "loss": 0.0742,
      "step": 550
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.6769890785217285,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.1647,
      "step": 560
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.05725250393152237,
      "learning_rate": 1.43e-05,
      "loss": 0.003,
      "step": 570
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.057429227977991104,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 0.0335,
      "step": 580
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.04723852872848511,
      "learning_rate": 1.41e-05,
      "loss": 0.0443,
      "step": 590
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.05079858750104904,
      "learning_rate": 1.4e-05,
      "loss": 0.0086,
      "step": 600
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.09702008217573166,
      "learning_rate": 1.39e-05,
      "loss": 0.0599,
      "step": 610
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.01141886506229639,
      "learning_rate": 1.38e-05,
      "loss": 0.0144,
      "step": 620
    },
    {
      "epoch": 0.315,
      "grad_norm": 42.58903503417969,
      "learning_rate": 1.3700000000000003e-05,
      "loss": 0.0518,
      "step": 630
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.14127463102340698,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0055,
      "step": 640
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.04546886309981346,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0586,
      "step": 650
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.267520546913147,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0791,
      "step": 660
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.03776255622506142,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 0.0971,
      "step": 670
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.025737646967172623,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.1526,
      "step": 680
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.05382919684052467,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 0.0797,
      "step": 690
    },
    {
      "epoch": 0.35,
      "grad_norm": 29.324459075927734,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.103,
      "step": 700
    },
    {
      "epoch": 0.355,
      "grad_norm": 10.620820045471191,
      "learning_rate": 1.2900000000000002e-05,
      "loss": 0.1525,
      "step": 710
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.07478582859039307,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.034,
      "step": 720
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.05172377824783325,
      "learning_rate": 1.27e-05,
      "loss": 0.037,
      "step": 730
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.015352478250861168,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0428,
      "step": 740
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.023255322128534317,
      "learning_rate": 1.25e-05,
      "loss": 0.0039,
      "step": 750
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1988351196050644,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0086,
      "step": 760
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.040043577551841736,
      "learning_rate": 1.23e-05,
      "loss": 0.0015,
      "step": 770
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.16234785318374634,
      "learning_rate": 1.22e-05,
      "loss": 0.0305,
      "step": 780
    },
    {
      "epoch": 0.395,
      "grad_norm": 4.049293518066406,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 0.0905,
      "step": 790
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.019366664811968803,
      "learning_rate": 1.2e-05,
      "loss": 0.0018,
      "step": 800
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.47994232177734375,
      "learning_rate": 1.1900000000000001e-05,
      "loss": 0.0116,
      "step": 810
    },
    {
      "epoch": 0.41,
      "grad_norm": 10.72220516204834,
      "learning_rate": 1.18e-05,
      "loss": 0.026,
      "step": 820
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.011060234159231186,
      "learning_rate": 1.17e-05,
      "loss": 0.19,
      "step": 830
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.018446190282702446,
      "learning_rate": 1.16e-05,
      "loss": 0.0223,
      "step": 840
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.03701566904783249,
      "learning_rate": 1.15e-05,
      "loss": 0.0022,
      "step": 850
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.012658283114433289,
      "learning_rate": 1.14e-05,
      "loss": 0.0027,
      "step": 860
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.009889701381325722,
      "learning_rate": 1.13e-05,
      "loss": 0.0013,
      "step": 870
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.372124195098877,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0458,
      "step": 880
    },
    {
      "epoch": 0.445,
      "grad_norm": 0.01415908895432949,
      "learning_rate": 1.1100000000000002e-05,
      "loss": 0.0631,
      "step": 890
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.014109622687101364,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.1002,
      "step": 900
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.009629962034523487,
      "learning_rate": 1.0900000000000002e-05,
      "loss": 0.0468,
      "step": 910
    },
    {
      "epoch": 0.46,
      "grad_norm": 25.1281681060791,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.1689,
      "step": 920
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.010114267468452454,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 0.0737,
      "step": 930
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.018361307680606842,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.0245,
      "step": 940
    },
    {
      "epoch": 0.475,
      "grad_norm": 5.737582206726074,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.1562,
      "step": 950
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0985263586044312,
      "learning_rate": 1.04e-05,
      "loss": 0.0385,
      "step": 960
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.16954278945922852,
      "learning_rate": 1.0300000000000001e-05,
      "loss": 0.1545,
      "step": 970
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.01668868027627468,
      "learning_rate": 1.02e-05,
      "loss": 0.0901,
      "step": 980
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.012748227454721928,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 0.0548,
      "step": 990
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.07318881899118423,
      "learning_rate": 1e-05,
      "loss": 0.0129,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1059739189248000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
